{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```\n",
    "                            (#%(//***,.                                         \n",
    "                          %@&&&&&&&&%&&&&&&#                                    \n",
    "                       ,@@@@@&&%#(/*,,*(#%&&@&. ,#%&&&&&@&&#,                   \n",
    "                      %&@@@@&&%(*,.....,*(#%&&@&&@@@@@&%&&@@@@@@@&              \n",
    "                     /%@&@@@&%%(/******/(##%&&@@&@@&#((////(((#%&@@@@           \n",
    "            /&@@@@@@&%@@@&@@&%%###(((#%%%&&&&&&&##%&#///*/(&@@@&%%&@@@#         \n",
    "        (@@@@&/@@@@@@@@#%@@@@&&%%%%*/#&%#%&&&@@@@@@&#//&%                       \n",
    "      @@@&&((##(%&@@@@@@&%@%@&@(%#%%%%%%,./(/.(/&((&@.                          \n",
    "    &@@%//***,****(#%&@@@@@@@@%&*/#/.*(///*,//.#%%,&                            \n",
    "   &@@(/**,,,,,,,,,,/&&@@@@@@@@&. ((/  /#%####%&&&(&                            \n",
    "  &@@#(#%@@@&*        %@@@@@@@@&*#%&/%((((%&&%%&&@@&                            \n",
    " .@@@@@                   (#&&&&@@@@&&&//,,,(/(##/                             ,\n",
    " .@&                      %@@&&(%(,*(/,..*(#/(%#((#%(.                       ,.@\n",
    "  .                   .(&%&@@@&%##**(#@/,  %@%%@#/#,%&&&                    ,.@@\n",
    "                  *%&@@&(/#%&@&@@@#(.. .,,*/*&@@@///,%%&@%                 ,.@@@\n",
    "                &@@@&&&%&@*,(#@@&@@@@@@(. ,&@&%@@&(,%,&&@@/              .,(@@@@\n",
    "               &@@%%(/#%&@@,,*(%@%@@@@@@@&##/(%&&%&#/#&@@@&           ..*.@@@@@@\n",
    "               @@@&%%%&&&@@@,%,&%&&&@@&%((&(%&@@@@%@#&&&&&@&.        ..*,@@@@@@@\n",
    "               #@@@&%(((%&&@%#,(%%@@&@&%*@@@@@@@@@@@%@&&/(#&&*...  ...*,@@@@@@@@\n",
    "               .%&&&(  ,(%&&@&*(&&&&&%/,&@&(@@&%&@@@&@@@&**#&&&,. ../*(@@@@@@@@&\n",
    "         .......%&@@@&&&@@@@@&/&&&%%#/(&@&(%%@%%%%@&@&&@@&&./#%%* ./*&@@@@@@@@@@\n",
    "##############(,*@@&&&&&&&@@@&&@@@@&#*#&&@&#%&%%#%%%@@&%@&&&#,(%&%*/@@@@@@@@@@@@\n",
    "##############(*.@@@%%#&&&@@@&@&%#(*#&@&#(#&&%&&##(,%&&&%%&@&&&@%/&@@@@@@@@@@@@@\n",
    "((##########(((/.%@@@#(#%&&@&&&%(*,(#%%&&(%#%#%&%#(,.#%&@@&@(,,%*#@@@@@@@@@@@@@@\n",
    "//(##########(,...@@@@@&&%@@&&%#((#%&&&%&%%&%%%&&%    ##%&@@@@/*&%@@@@@@@@@@@@@@\n",
    "(###########((/,,.(@@@&/,(@&&&&%%&&&&&%%&&&%%%%&&........%%%%**@@@@@@@@&@@@@@@@@\n",
    "###(,,,,*/(((((*,(%@@@@@@@@&&&&&&&@&%/&&%#%%%%&&#./#(*//(((%*/@@@@@@@@@@@@@@@@@@\n",
    ",*###(((((((((((#&&@@&@@@@&@@&&@@&&(&#**,**,,,********//((%*#@@@@@@@@@@@@@@@@@@@\n",
    "///////////////(#%&&@@&@@@@@@@@@&(**,*,,,,,,,,,*%//%##(##(*&@@@@@@@@@@@@@@@@@@@@\n",
    "///////////////////(##%&@@@@@@@&%******&/(##%###########/*@@@@@@@@@@@@@@@@@@@@@@\n",
    "////////////////////((#%%%%&@@@&&#,(/#%*,*/*.&%########//@@@@@@@@@@@@@@@@@@@@@@&\n",
    "%%(*/////////////////////(///////#@@@@@@@@/(%*,*/(.,&&*(@@@@@@@@@@@@@@@@@@@@@@(/\n",
    "```\n",
    "# Goblin Mode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ignore this\n",
    "# This is the version of torch I am using if you happen to be on windows and have a decent GPU.\n",
    "# pip install torch==1.7.1+cu110 torchvision==0.8.2+cu110 torchaudio==0.7.2 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import cv2\n",
    "import copy\n",
    "import json\n",
    "import math\n",
    "import numpy as np\n",
    "from time import time\n",
    "import mediapipe as mp\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "INFO: Created TensorFlow Lite XNNPACK delegate for CPU.\n"
     ]
    }
   ],
   "source": [
    "# Initializing mediapipe pose class.\n",
    "mp_pose = mp.solutions.pose\n",
    "\n",
    "# Setting up the Pose function.\n",
    "pose = mp_pose.Pose(static_image_mode=True, min_detection_confidence=0.3, model_complexity=2)\n",
    "\n",
    "# Initializing mediapipe drawing class, useful for annotation.\n",
    "mp_drawing = mp.solutions.drawing_utils "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "myPath = os.getcwd()\n",
    "myYogaPath = os.path.join(myPath, 'yoga')\n",
    "myYogaFolders = os.listdir(myYogaPath)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_chechpoint(myPath):\n",
    "    goodFile = open(os.path.join(myPath, 'good.json'), 'r')\n",
    "    badFile = open(os.path.join(myPath, 'bad.json'), 'r')\n",
    "    goods = json.load(goodFile)\n",
    "    bads = json.load(badFile)\n",
    "    goodFile.close()\n",
    "    badFile.close()\n",
    "    return goods, bads\n",
    "\n",
    "def save_chechpoint(goods, bads):\n",
    "    good_json = json.dumps(goods, indent = 4) \n",
    "    bad_object = json.dumps(bads, indent = 4) \n",
    "    with open(\"good.json\", \"w\") as good_file:\n",
    "        good_file.write(good_json)\n",
    "    with open(\"bad.json\", \"w\") as bad_file:\n",
    "        bad_file.write(bad_object)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def detectPose(image, pose, display=True):\n",
    "    '''\n",
    "    This function performs pose detection on an image.\n",
    "    Args:\n",
    "        image: The input image with a prominent person whose pose landmarks needs to be detected.\n",
    "        pose: The pose setup function required to perform the pose detection.\n",
    "        display: A boolean value that is if set to true the function displays the original input image, the resultant image, \n",
    "                 and the pose landmarks in 3D plot and returns nothing.\n",
    "    Returns:\n",
    "        output_image: The input image with the detected pose landmarks drawn.\n",
    "        landmarks: A list of detected landmarks converted into their original scale.\n",
    "    '''\n",
    "    \n",
    "    # Create a copy of the input image.\n",
    "    output_image = None\n",
    "    try:\n",
    "        output_image = image.copy()\n",
    "    except:\n",
    "        print('bad image')\n",
    "        return 'bad'\n",
    "    \n",
    "    # Convert the image from BGR into RGB format.\n",
    "    imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "    \n",
    "    # Perform the Pose Detection.\n",
    "    results = pose.process(imageRGB)\n",
    "    \n",
    "    # Retrieve the height and width of the input image.\n",
    "    height, width, _ = image.shape\n",
    "    \n",
    "    # Initialize a list to store the detected landmarks.\n",
    "    landmarks = []\n",
    "    \n",
    "    # Check if any landmarks are detected.\n",
    "    if results.pose_landmarks:\n",
    "        \n",
    "        # TODO auto detect images that have a small percent of landmarks\n",
    "\n",
    "        # Draw Pose landmarks on the output image.\n",
    "        mp_drawing.draw_landmarks(image=output_image, landmark_list=results.pose_landmarks,\n",
    "                                  connections=mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "        # Iterate over the detected landmarks.\n",
    "        for landmark in results.pose_landmarks.landmark:\n",
    "            \n",
    "            # Append the landmark into the list.\n",
    "            landmarks.append((int(landmark.x * width), int(landmark.y * height),\n",
    "                                  (landmark.z * width)))\n",
    "            \n",
    "    else:\n",
    "        print('bad image')\n",
    "        return 'bad'\n",
    "    \n",
    "    # Check if the original input image and the resultant image are specified to be displayed.\n",
    "    if display:\n",
    "    \n",
    "        # Display the original input image and the resultant image.\n",
    "        # plt.figure(figsize=[22,22])\n",
    "        # plt.subplot(122);plt.imshow(output_image[:,:,::-1]);plt.title(\"Output Image\");plt.axis('off');\n",
    "        \n",
    "        # Also Plot the Pose landmarks in 3D.\n",
    "        mp_drawing.plot_landmarks(results.pose_world_landmarks, mp_pose.POSE_CONNECTIONS)\n",
    "        \n",
    "    # Otherwise\n",
    "    else:\n",
    "        \n",
    "        # Return the output image and the found landmarks.\n",
    "        return output_image, landmarks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This is a quick tool I made to filter out images that the pose estimator does poorly on.\n",
    "# See good and bad json. \n",
    "# To use, press play, then you'll see an image with the pose estimation on top.\n",
    "# If the pose estimation is good, simply press enter in the command prompt and it will be added to good.\n",
    "# If the estimation is bad, enter 'k', and if you'd like to skip to the next pose category, enter 's'.\n",
    "# Finally enter 's' again if you'd like to exit the tool.\n",
    "# Do not just pause the notebook because your progress will not be stored in the json files.\n",
    "\n",
    "# This is just one possible (partial) solution, by no means do I think we NEED to do this right away.\n",
    "\n",
    "goods, bads = load_chechpoint(myPath)\n",
    "\n",
    "for folder in myYogaFolders:\n",
    "\n",
    "    print(folder)\n",
    "    posePath = os.path.join(myYogaPath, folder)\n",
    "    myYogaImages = os.listdir(posePath)\n",
    "\n",
    "\n",
    "    finished = True\n",
    "    for imageName in myYogaImages:\n",
    "\n",
    "        if imageName in goods[folder] or imageName in bads[folder]:\n",
    "            continue\n",
    "\n",
    "        finished = False\n",
    "        imagePath = os.path.join(posePath, imageName)\n",
    "        image = cv2.imread(imagePath)\n",
    "        attempt = detectPose(image, pose, display=True)\n",
    "\n",
    "        if attempt == 'bad':\n",
    "            bads[folder].append(imageName)\n",
    "            continue\n",
    "        \n",
    "        x = input()\n",
    "        if x == 'b':\n",
    "            bads[folder].append(imageName)\n",
    "        elif x == 'g':\n",
    "            goods[folder].append(imageName)\n",
    "        else:\n",
    "            break\n",
    "        \n",
    "        clear_output(wait=True)\n",
    "\n",
    "    clear_output(wait=True)\n",
    "\n",
    "    if finished:\n",
    "        continue\n",
    "    \n",
    "    x = input('press enter to end')\n",
    "    if x == '':\n",
    "        print('saving progress')\n",
    "        break\n",
    "\n",
    "save_chechpoint(goods, bads)\n",
    "\n",
    "# TODO - Perhaps just run on everything, and store the landmarks for each image,\n",
    "# then go back through and count average number of landmarks for category to get a better\n",
    "# idea of which poses the estimator is doing a good job at."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "NotADirectoryError",
     "evalue": "[Errno 20] Not a directory: '/mnt/c/users/Fizza/documents/eecs/eecs448/project/DG_Capstone/yoga/Akarna_Dhanurasana.txt'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNotADirectoryError\u001b[0m                        Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 6\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m folder \u001b[39min\u001b[39;00m myYogaFolders:\n\u001b[1;32m      5\u001b[0m     posePath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(myYogaPath, folder)\n\u001b[0;32m----> 6\u001b[0m     myYogaImages \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39;49mlistdir(posePath)\n\u001b[1;32m      8\u001b[0m     \u001b[39mfor\u001b[39;00m imageName \u001b[39min\u001b[39;00m myYogaImages:\n\u001b[1;32m     10\u001b[0m         imagePath \u001b[39m=\u001b[39m os\u001b[39m.\u001b[39mpath\u001b[39m.\u001b[39mjoin(posePath, imageName)\n",
      "\u001b[0;31mNotADirectoryError\u001b[0m: [Errno 20] Not a directory: '/mnt/c/users/Fizza/documents/eecs/eecs448/project/DG_Capstone/yoga/Akarna_Dhanurasana.txt'"
     ]
    }
   ],
   "source": [
    "temp = None\n",
    "\n",
    "for folder in myYogaFolders:\n",
    "\n",
    "    posePath = os.path.join(myYogaPath, folder)\n",
    "    myYogaImages = os.listdir(posePath)\n",
    "\n",
    "    for imageName in myYogaImages:\n",
    "\n",
    "        imagePath = os.path.join(posePath, imageName)\n",
    "        image = cv2.imread(imagePath)\n",
    "        imageRGB = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        results = pose.process(imageRGB)\n",
    "        if results:\n",
    "            temp = results\n",
    "            break\n",
    "    break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "forMedia",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "ca103a73504f546ece912beb0e22110d06c2f833e99fc57d6bf4b25d9b1ae21c"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
